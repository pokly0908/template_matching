{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72cdf66e-db20-45e2-bca4-9aadf876eaa8",
   "metadata": {},
   "source": [
    "# Template_Matching\n",
    "1.img 는 도로의 이미지입니다.<br/>\n",
    "(park_1.png, park_2.png, park_3.png, road_1jpg, road_2.jpg)<br/>\n",
    "2. template은 표지판 이미지입니다 각 template는 도로이미지에서 따왔습니다.<br/> \n",
    "(ex_park1.png, ex_park2.png, ex_park3.png, parking_sign.png, slipery_road1.png, ex_slip.png)\n",
    "\n",
    "'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF_NORMED' 이 3개는 서로 다른 비교방법 입니다.<br/>\n",
    "(https://cord-ai.tistory.com/86) 이거 보시면 알 것 같아요\n",
    "\n",
    "CCOEFF = 같으면 1, 연관성 없으면 0, 역일치 -1<br/>\n",
    "CCORR = 같으면 큰값, 다르면 작은 값<br/>\n",
    "SQDIFF = 같으면 0, 다르면 값이큼<br/>\n",
    "하지만 보기편하게 백분률로 바꿔놨습니다.\n",
    "\n",
    "\n",
    "매칭 결과는 사각형 으로 표시가 됩니다.\n",
    "\n",
    "img 내에서 template를 찾는건데 이미지 크기도 중요한 것 같습니다.<br/>\n",
    "(https://076923.github.io/posts/Python-opencv-37/) 이거 보시면 될 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14f2dbd2-53e8-43f7-8583-4ab9cb5c748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2.TM_CCOEFF_NORMED -0.3776586055755615 0.27199849486351013 (445, 168) (4, 212)\n",
      "cv2.TM_CCORR_NORMED 0.6908811330795288 0.9495624303817749 (1, 505) (668, 60)\n",
      "cv2.TM_SQDIFF_NORMED 0.10346263647079468 1.0 (668, 71) (201, 324)\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 매칭으로 객체 위치 검출 (template_matching.py)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 입력이미지와 템플릿 이미지 읽기\n",
    "img = cv2.imread('./img/park2.png')\n",
    "#img = cv2.resize(img, (640, 480))\n",
    "template = cv2.imread('./img/ex_park1.png')\n",
    "th, tw = template.shape[:2]\n",
    "cv2.imshow('template', template)\n",
    "\n",
    "# 3가지 매칭 메서드 순회\n",
    "methods = ['cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR_NORMED', \\\n",
    "                                     'cv2.TM_SQDIFF_NORMED']\n",
    "for i, method_name in enumerate(methods):\n",
    "    img_draw = img.copy()\n",
    "    method = eval(method_name)\n",
    "    # 템플릿 매칭   ---①\n",
    "    res = cv2.matchTemplate(img, template, method)\n",
    "    # 최솟값, 최댓값과 그 좌표 구하기 ---②\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    print(method_name, min_val, max_val, min_loc, max_loc)\n",
    "\n",
    "    # TM_SQDIFF의 경우 최솟값이 좋은 매칭, 나머지는 그 반대 ---③\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "        match_val = round((1 - min_val), 3) * 100\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "        match_val = round(max_val, 3) * 100\n",
    "    # 매칭 좌표 구해서 사각형 표시   ---④      \n",
    "    bottom_right = (top_left[0] + tw, top_left[1] + th)\n",
    "    cv2.rectangle(img_draw, top_left, bottom_right, (0,0,255),2)\n",
    "    # 매칭 포인트 표시 ---⑤\n",
    "    cv2.putText(img_draw, str(match_val) + \"%\", top_left, \\\n",
    "                cv2.FONT_HERSHEY_PLAIN, 2,(0,255,0), 1, cv2.LINE_AA)\n",
    "    cv2.imshow(method_name, img_draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f279d6-c39d-4869-bb97-0f5660ca1c18",
   "metadata": {},
   "source": [
    "# MultiScale_Template_Matching\n",
    "\n",
    "위 코드와 다른점은 template이미지를 scales로 크기를 바꿔가면서 img와 비교하는 알고리즘입니다.<br/>\n",
    "Template Matching 알고리즘의 단점인 template이미지 사이즈 이슈를 해결할 수 있는 것 같아요.\n",
    "\n",
    "cv2.COLOR_BGR2GRAY는 cv2.COLOR_BGR2GRAY, cv2.COLOR_BGR2HSV, cv2.COLOR_BGR2RGB 이렇게 바꿔가면서 비교해봐도 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5283d497-0082-458b-aa89-e15f03fc84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def multi_scale_template_matching(img, template):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    methods = ['cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF_NORMED']\n",
    "    \n",
    "    for i, method_name in enumerate(methods):\n",
    "        img_draw = img.copy()\n",
    "        method = eval(method_name)\n",
    "        \n",
    "        # 다양한 크기의 템플릿 생성\n",
    "        scales = [0.3, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4]\n",
    "        \n",
    "        for scale in scales:\n",
    "            resized_template = cv2.resize(template_gray, (int(template.shape[1]*scale), int(template.shape[0]*scale)))\n",
    "            \n",
    "            res = cv2.matchTemplate(img_gray, resized_template, method)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "            if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "                top_left = min_loc\n",
    "                match_val = round((1 - min_val), 3) * 100\n",
    "            else:\n",
    "                top_left = max_loc\n",
    "                match_val = round(max_val, 3) * 100\n",
    "            \n",
    "            bottom_right = (top_left[0] + int(template.shape[1]*scale), top_left[1] + int(template.shape[0]*scale))\n",
    "            \n",
    "            cv2.rectangle(img_draw, top_left, bottom_right, (0, 0, 255), 2)\n",
    "            cv2.putText(img_draw, f\"{scale}: {match_val} %\", (top_left[0], top_left[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(f\"{method_name} - Multi-Scale\", img_draw)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 입력이미지와 템플릿 이미지 읽기\n",
    "img = cv2.imread('./img/road_1.jpg')\n",
    "img = cv2.resize(img, (640, 853))\n",
    "template = cv2.imread('./img/ex_park3.png')\n",
    "\n",
    "# Multi-Scale Template Matching 적용\n",
    "multi_scale_template_matching(img, template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233da70c-7955-4978-a2bf-50cb3f27dfff",
   "metadata": {},
   "source": [
    "#multi_scale_multi_template_matching\n",
    "\n",
    "template이미지를 여러개 비교\n",
    "\n",
    "(cv2.COLOR_BGR2HSV, cv2.TM_CCOEFF_NORMED)가 정확도 높았음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20fd87ce-facd-48c7-a180-2821a427ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def multi_scale_multi_template_matching(img, templates):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    methods = ['cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF_NORMED']\n",
    "    \n",
    "    for i, method_name in enumerate(methods):\n",
    "        img_draw = img.copy()\n",
    "        method = eval(method_name)\n",
    "        \n",
    "        max_match_val = 0  # 가장 높은 매칭 점수를 저장하는 변수\n",
    "        best_scale = 0  # 가장 높은 매칭 점수를 갖는 스케일을 저장하는 변수\n",
    "        best_top_left = (0, 0)  # 가장 높은 매칭 점수를 갖는 좌표를 저장하는 변수\n",
    "        \n",
    "        for template in templates:\n",
    "            template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "            # 다양한 크기의 템플릿 생성\n",
    "            scales = [0.3, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4]\n",
    "            \n",
    "            for scale in scales:\n",
    "                resized_template = cv2.resize(template_gray, (int(template.shape[1]*scale), int(template.shape[0]*scale)))\n",
    "                \n",
    "                res = cv2.matchTemplate(img_gray, resized_template, method)\n",
    "                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "                if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "                    match_val = round((1 - min_val), 3) * 100\n",
    "                else:\n",
    "                    match_val = round(max_val, 3) * 100\n",
    "\n",
    "                if match_val > max_match_val:\n",
    "                    max_match_val = match_val\n",
    "                    best_scale = scale\n",
    "                    best_top_left = max_loc if method not in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED] else min_loc\n",
    "        \n",
    "        # 매칭 좌표 구해서 사각형 표시\n",
    "        best_bottom_right = (best_top_left[0] + int(template.shape[1] * best_scale), best_top_left[1] + int(template.shape[0] * best_scale))\n",
    "        cv2.rectangle(img_draw, best_top_left, best_bottom_right, (0, 0, 255), 2)\n",
    "        cv2.putText(img_draw, f\"Best Match ({best_scale}): {max_match_val} %\", (best_top_left[0], best_top_left[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(f\"{method_name} - Multi-Scale Multi-Template\", img_draw)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 입력이미지와 여러 템플릿 이미지 읽기\n",
    "img = cv2.imread('./img/road_1.jpg')\n",
    "img = cv2.resize(img, (640, 853))\n",
    "template1 = cv2.imread('./img/ex_park1.png')\n",
    "template2 = cv2.imread('./img/ex_park2.png')\n",
    "template3 = cv2.imread('./img/ex_park3.png')\n",
    "\n",
    "# 여러 템플릿 적용\n",
    "templates = [template1, template2, template3]\n",
    "multi_scale_multi_template_matching(img, templates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc2171-aa3f-448f-8a24-9b6458a52ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
